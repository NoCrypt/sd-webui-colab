{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfKvWAVnz8OB"
      },
      "source": [
        "<details>\n",
        "  <summary><b>Credits</b></summary>\n",
        "\tColab that I've forked and edits:\n",
        "\n",
        "- https://github.com/daswer123/stable-diffusion-colab\n",
        "- https://github.com/acheong08/Diffusion-ColabUI\n",
        "- https://github.com/TheLastBen/fast-stable-diffusion\n",
        "- https://colab.research.google.com/drive/1Iy-xW9t1-OQWhb0hNxueGij8phCyluOh\n",
        "- https://colab.research.google.com/drive/1T8NKPZknFrylmUMAGLsSqUJ9QEgQBs_3\n",
        "- And some chinese colab that I can't share to public :D\n",
        "\n",
        "</details>\n",
        "\n",
        "<fieldset>\n",
        "    <legend>\n",
        "    <h2><b>How to use?</b></h2>\n",
        "    </legend>\n",
        "\n",
        "1. Edit the settings by checking the checkbox to your liking\n",
        "2. Run the cell by clicking ‚ñ∂Ô∏è button, from top to bottom\n",
        "3. After running the start webui cell, wait for few minutes until it says \"Connected\" then click on the link above it. (not 127.0.0.1)\n",
        "</fieldset>\n",
        "\n",
        "<br>\n",
        "\n",
        "If something is broken, [dm me.](https://lookup.guru/442099748669751297)\n",
        "\n",
        "Need to mirror models? [check my new tool here](https://colab.research.google.com/drive/1aQ5nXTfLWHhZi7GOfXteLKg5OT1X-aBZ?)\n",
        "\n",
        "Have a copy of this colab? [Check update here.](https://colab.research.google.com/github/NoCrypt/sd-webui-colab/blob/main/sd-webui-colab.ipynb)\n",
        "\n",
        "\n",
        "## **Latest Changes [27/11]**\n",
        "- Added gyokai model. <font color=gray>How tf I forgot lmao...</font>\n",
        "- Added upload models to huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DJ7Yzy8Asu3Y"
      },
      "outputs": [],
      "source": [
        "#@title # **üëá Test your GPU runtime**\n",
        "import os\n",
        "from subprocess import getoutput\n",
        "\n",
        "def increase_font():\n",
        "  from IPython.display import Javascript\n",
        "  display(Javascript('''\n",
        "  for (rule of document.styleSheets[0].cssRules){\n",
        "    if (rule.selectorText=='body') {\n",
        "      rule.style.fontSize = '45px'\n",
        "      rule.style.fontWeight = '600'\n",
        "      break\n",
        "    }\n",
        "  }\n",
        "  '''))\n",
        "\n",
        "output = getoutput('nvidia-smi --query-gpu=gpu_name --format=csv')\n",
        "increase_font()\n",
        "if \"name\" in output:\n",
        "  print('\u001b[32mGPU Connected! Currently using', output[5:], \"‚úÖ\") \n",
        "  print('You may continue.')\n",
        "else:\n",
        "  print(\"\\033[91mNo GPU accelerator is connected. \\nPlease connect to a GPU Runtime\")\n",
        "print(\"\\033[0m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sBbcB4vwj_jm"
      },
      "outputs": [],
      "source": [
        "#@title # **üëá Install Depedencies**\n",
        "%cd /content\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import time\n",
        "from subprocess import getoutput\n",
        "\n",
        "#@markdown ## **Options**\n",
        "run_in_gdrive = False #@param {type:\"boolean\"}\n",
        "root_dir = \"/content\"\n",
        "if run_in_gdrive:\n",
        "  if not os.path.exists('/content/gdrive'):\n",
        "    drive.mount('/content/gdrive')\n",
        "  !mkdir -p {'/content/gdrive/MyDrive/WebUI'}\n",
        "  root_dir = \"/content/gdrive/MyDrive/WebUI\"\n",
        "#@markdown - run_in_gdrive is a bit experimental, try at your own risk.\n",
        "\n",
        "# Ah yes, xformers\n",
        "xformers = False #@param {type:\"boolean\"}\n",
        "if xformers:\n",
        "  if 'T4' in getoutput('nvidia-smi --query-gpu=gpu_name --format=csv'):\n",
        "    # !pip install -U --pre triton\n",
        "    !pip install -q https://github.com/NoCrypt/xfromers_builds_colab/releases/download/3456388070/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl\n",
        "  else:\n",
        "    print(\"[XFORMERS] GPU isn't supported.\")\n",
        "    xformers = False\n",
        "#@markdown - xformers is a bit experimental, won't support hypernetworks but gives 1.2x perfomance increase\n",
        "\n",
        "# This function will delete the path if exists in drive (reinstall)\n",
        "def rm_drive_path(path):\n",
        "  if run_in_gdrive:\n",
        "    if os.path.exists(root_dir+\"/stable-diffusion-webui/\"+path):\n",
        "      !rm -rf {root_dir}/stable-diffusion-webui/{path}\n",
        "\n",
        "# Install Automatic1111's Webui (or update if already exists)\n",
        "if os.path.exists(root_dir+\"/stable-diffusion-webui\"):\n",
        "  %cd {root_dir}/stable-diffusion-webui/\n",
        "  !git pull\n",
        "else:\n",
        "  !git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui {root_dir}/stable-diffusion-webui\n",
        "  %cd {root_dir}/stable-diffusion-webui/\n",
        "\n",
        "# Custom Configuration\n",
        "custom_config = True #@param {type:\"boolean\"}\n",
        "if custom_config:\n",
        "  !wget -O styles.csv https://raw.githubusercontent.com/NoCrypt/webui-settings/main/styles.csv\n",
        "  !wget -O config.json https://raw.githubusercontent.com/NoCrypt/webui-settings/main/config.json\n",
        "  !wget -O ui-config.json https://raw.githubusercontent.com/NoCrypt/webui-settings/main/ui-config.json\n",
        "  !wget -O user.css https://raw.githubusercontent.com/NoCrypt/webui-settings/main/user.css\n",
        "\n",
        "# Output images to drive\n",
        "output_to_drive = True #@param{type:\"boolean\"}\n",
        "if output_to_drive:\n",
        "  if not os.path.exists('/content/gdrive'):\n",
        "    drive.mount('/content/gdrive')\n",
        "  !sed -i 's@\"outdir_txt2img_samples\": \"outputs/txt2img-images\"@\"outdir_txt2img_samples\": \"/content/gdrive/MyDrive/nai-outputs/txt2img-images\"@' {root_dir}/stable-diffusion-webui/config.json\n",
        "  !sed -i 's@\"outdir_img2img_samples\": \"outputs/img2img-images\"@\"outdir_img2img_samples\": \"/content/gdrive/MyDrive/nai-outputs/img2img-images\"@' {root_dir}/stable-diffusion-webui/config.json\n",
        "  !sed -i 's@\"outdir_extras_samples\": \"outputs/extras-images\"@\"outdir_extras_samples\": \"/content/gdrive/MyDrive/nai-outputs/extras-images\"@' {root_dir}/stable-diffusion-webui/config.json\n",
        "  !sed -i 's@\"outdir_txt2img_grids\": \"outputs/txt2img-grids\"@\"outdir_txt2img_grids\": \"/content/gdrive/MyDrive/nai-outputs/txt2img-grids\"@' {root_dir}/stable-diffusion-webui/config.json\n",
        "  !sed -i 's@\"outdir_img2img_grids\": \"outputs/img2img-grids\"@\"outdir_img2img_grids\": \"/content/gdrive/MyDrive/nai-outputs/img2img-grids\"@' {root_dir}/stable-diffusion-webui/config.json\n",
        "  # !sed -i 's@\"outdir_extras_grids\": \"outputs/extras-grids\"@\"outdir_extras_grids\": \"/content/gdrive/MyDrive/nai-outputs/extras-grids\"@' {root_dir}/stable-diffusion-webui/config.json\n",
        "  !sed -i 's@\"outdir_save\": \"log/images\"@\"outdir_save\": \"/content/gdrive/MyDrive/nai-outputs/log/images\"@' {root_dir}/stable-diffusion-webui/config.json\n",
        "\n",
        "#@markdown - output_to_drive needs custom_config to be activated\n",
        "\n",
        "#@markdown ## <br>**Extension**\n",
        "#@markdown - I aware that there's already an extension tab. Think of these as something you want to pre-install for saving time.\n",
        "\n",
        "# Add Dynamic Prompt\n",
        "add_dynamic_prompting = False #@param{type:\"boolean\"}\n",
        "if add_dynamic_prompting:\n",
        "  rm_drive_path('extensions/dynamic-prompts')\n",
        "  !git clone https://github.com/adieyal/sd-dynamic-prompting/ extensions/dynamic-prompts\n",
        "\n",
        "# Add Wildcards\n",
        "add_wildcards = False #@param{type:\"boolean\"}\n",
        "if add_wildcards:\n",
        "  rm_drive_path('extensions/wildcards')\n",
        "  !git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui-wildcards extensions/wildcards\n",
        "\n",
        "# Add novelai_converter\n",
        "add_novelai_converter = True #@param{type:\"boolean\"}\n",
        "if add_novelai_converter:\n",
        "  rm_drive_path('extensions/novelai-2-local-prompt')\n",
        "  !git clone https://github.com/animerl/novelai-2-local-prompt.git extensions/novelai-2-local-prompt\n",
        "\n",
        "# Add UmiAI\n",
        "add_UmiAI = True #@param{type:\"boolean\"}\n",
        "#@markdown - [UmiAI info](https://www.patreon.com/posts/umi-ai-official-73544634)\n",
        "if add_UmiAI:\n",
        "  rm_drive_path('extensions/UnivAICharGen')\n",
        "  !git clone https://github.com/Klokinator/UnivAICharGen.git extensions/UnivAICharGen\n",
        "\n",
        "\n",
        "# Add booru tag suggestion by DominikDoom\n",
        "add_prompt_suggestion = True #@param{type:\"boolean\"}\n",
        "# prompt_suggestion_wildcard_support = False #@param{type:\"boolean\"}\n",
        "# prompt_suggestion_embed_support = False #@param{type:\"boolean\"}\n",
        "# if add_prompt_suggestion:\n",
        "#   %cd {root_dir}\n",
        "#   !git clone https://github.com/DominikDoom/a1111-sd-webui-tagcomplete temp\n",
        "#   %cd temp\n",
        "#   !git reset --hard dc77b3f17f #Because DominikDoom is a bit... f*cked up.\n",
        "#   !rm -fr .git #.git folder can cause havoc since I used old version of tagcomplete (since it's script based not extension based yet)\n",
        "#   !cp -vr . {root_dir}/stable-diffusion-webui/\n",
        "#   !rm -rf {root_dir}/temp/\n",
        "#   %cd {root_dir}/stable-diffusion-webui/\n",
        "#   if not prompt_suggestion_wildcard_support:\n",
        "#     !sed -i 's@rds\": true@rds\": false@' ./tags/config.json\n",
        "#   if not prompt_suggestion_embed_support:\n",
        "#     !sed -i 's@ngs\": true@ngs\": false@' ./tags/config.json\n",
        "if add_prompt_suggestion:\n",
        "  rm_drive_path('extensions/a1111-sd-webui-tagcomplete')\n",
        "  %cd {root_dir}/stable-diffusion-webui\n",
        "  !git clone https://github.com/DominikDoom/a1111-sd-webui-tagcomplete extensions/a1111-sd-webui-tagcomplete\n",
        "#   %cd {root_dir}/stable-diffusion-webui/extensions/tag-autocomplete/\n",
        "#   if not prompt_suggestion_wildcard_support:\n",
        "#     !sed -i 's@rds\": true@rds\": false@' ./tags/config.json\n",
        "#   if not prompt_suggestion_embed_support:\n",
        "#     !sed -i 's@ngs\": true@ngs\": false@' ./tags/config.json\n",
        "#   %cd {root_dir}/stable-diffusion-webui\n",
        "\n",
        "# Add deepdanbooru to arguments\n",
        "add_deepdanbooru = False #@param {type:\"boolean\"} \n",
        "deepdanbooru_param = \"\"\n",
        "if add_deepdanbooru:\n",
        "  deepdanbooru_param = \"--deepdanbooru\"\n",
        "\n",
        "# Add Aesthetic Gradients\n",
        "add_aesthetic_gradients_support = False #@param {type:\"boolean\"} \n",
        "if add_aesthetic_gradients_support:\n",
        "  rm_drive_path('extensions/aesthetic-gradients')\n",
        "  !git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui-aesthetic-gradients extensions/aesthetic-gradients\n",
        "\n",
        "# Add Image History\n",
        "add_image_history = False #@param {type:\"boolean\"} \n",
        "if add_image_history:\n",
        "  rm_drive_path('extensions/images-browser')\n",
        "  !git clone https://github.com/yfszzx/stable-diffusion-webui-images-browser extensions/images-browser\n",
        "\n",
        "# Add Inspiration Extension Tab\n",
        "add_inspiration = False #@param {type:\"boolean\"} \n",
        "if add_inspiration:\n",
        "  rm_drive_path('extensions/stable-diffusion-webui-inspiration')\n",
        "  !git clone https://github.com/yfszzx/stable-diffusion-webui-inspiration extensions/stable-diffusion-webui-inspiration\n",
        "\n",
        "#@markdown ## <br>**Experimental üß™**\n",
        "#@markdown *Warning: don't check options below if you dont understand*\n",
        "#@markdown <br> *Don't report if options below is broken. It meant to be.*\n",
        "#@markdown <br> *I'll remove some of the options if it's already been implemented.*\n",
        "add_newest_sampler = False #@param {type:\"boolean\"} \n",
        "if add_newest_sampler:\n",
        "  !git fetch origin pull/4961/head:k-diffusion-update\n",
        "  !git checkout k-diffusion-update\n",
        "fix_xy_plot = True #@param {type:\"boolean\"} \n",
        "if fix_xy_plot:\n",
        "  !sed -i '77s/.*/    p.sampler_name = x/' {root_dir}/stable-diffusion-webui/scripts/xy_grid.py\n",
        "\n",
        "%cd {root_dir}/stable-diffusion-webui\n",
        "!COMMANDLINE_ARGS=\"--exit {deepdanbooru_param}\" REQS_FILE=\"requirements.txt\" python launch.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XS_wXAY3FOLx"
      },
      "outputs": [],
      "source": [
        "#@title # **üëá Install Models**\n",
        "\n",
        "from google.colab import drive\n",
        "import json\n",
        "import os\n",
        "%cd {root_dir}/stable-diffusion-webui/models/Stable-diffusion/\n",
        "\n",
        "# #@markdown ## **Drive Cookies ‚ö°**\n",
        "# !pip install gdown -U\n",
        "# jsonfile = json.loads(drive_cookies)\n",
        "# json_object = json.dumps(jsonfile,indent=1)\n",
        "# with open(\"/root/.cache/gdown/cookies.json\", \"w\") as outfile:\n",
        "#     outfile.write(json_object)\n",
        "\n",
        "def install_aria():\n",
        "  if not os.path.exists('/usr/bin/aria2c'):\n",
        "    !apt install -y -qq aria2\n",
        "\n",
        "#@markdown ## **From Huggingface ü§ó**\n",
        "#@markdown *custom token is optional, you can leave it empty if you want*\n",
        "custom_hf_token = \"\" #@param {type:\"string\"}\n",
        "def custom_hf_model(url, checkpoint_name=\"\"):\n",
        "  if not custom_hf_token:\n",
        "    user_token = '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'\n",
        "  else:\n",
        "    user_token = custom_hf_token\n",
        "  user_header = f\"\\\"Authorization: Bearer {user_token}\\\"\"\n",
        "  install_aria()\n",
        "  if checkpoint_name:\n",
        "    # !wget -c --show-progress --header={user_header} {url} -O {root_dir}/stable-diffusion-webui/models/Stable-diffusion/{checkpoint_name}.ckpt\n",
        "    !aria2c  --summary-interval=10 -c --header={user_header} -x 10 -k 1M -s 10 -d {root_dir}/stable-diffusion-webui/models/Stable-diffusion -o {checkpoint_name} {url}\n",
        "  else:\n",
        "    !aria2c  --summary-interval=10 -c --header={user_header} -x 10 -k 1M -s 10 -d {root_dir}/stable-diffusion-webui/models/Stable-diffusion/ {url}\n",
        "\n",
        "def custom_hf_hn(url, checkpoint_name=\"\"):\n",
        "  if not custom_hf_token:\n",
        "    user_token = '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'\n",
        "  else:\n",
        "    user_token = custom_hf_token\n",
        "  user_header = f\"\\\"Authorization: Bearer {user_token}\\\"\"\n",
        "  if checkpoint_name:\n",
        "    !aria2c  --summary-interval=10 -c --header={user_header} -x 10 -k 1M -s 10 -d {root_dir}/stable-diffusion-webui/models/hypernetworks -o {checkpoint_name} {url}\n",
        "  else:\n",
        "    !aria2c  --summary-interval=10 -c --header={user_header} -x 10 -k 1M -s 10 -d {root_dir}/stable-diffusion-webui/models/hypernetworks/ {url}\n",
        "\n",
        "def custom_hf_em(url, checkpoint_name=\"\"):\n",
        "  if not custom_hf_token:\n",
        "    user_token = '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'\n",
        "  else:\n",
        "    user_token = custom_hf_token\n",
        "  user_header = f\"\\\"Authorization: Bearer {user_token}\\\"\"\n",
        "  if checkpoint_name:\n",
        "    !aria2c  --summary-interval=10 -c --header={user_header} -x 10 -k 1M -s 10 -d {root_dir}/stable-diffusion-webui/embeddings -o {checkpoint_name} {url}\n",
        "  else:\n",
        "    !aria2c  --summary-interval=10 -c --header={user_header} -x 10 -k 1M -s 10 -d {root_dir}/stable-diffusion-webui/embeddings/ {url}\n",
        "\n",
        "\n",
        "Waifu_Diffusion = True #@param {'type':'boolean'}\n",
        "if Waifu_Diffusion:\n",
        "  custom_hf_model(\"https://huggingface.co/hakurei/waifu-diffusion-v1-3/resolve/main/wd-v1-3-float32.ckpt\", \"waifu_diffusion.ckpt\")\n",
        "\n",
        "Waifu_Diffusion_VAE = True #@param {'type':'boolean'}\n",
        "if Waifu_Diffusion_VAE:\n",
        "  custom_hf_model(\"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime2.ckpt\", \"waifu_diffusion.vae.pt\")\n",
        "\n",
        "unpickled_ANYTHING = True #@param {'type':'boolean'}\n",
        "if unpickled_ANYTHING:\n",
        "  custom_hf_model(\"https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/Anything-V3.0-pruned.ckpt\", \"un_anything.ckpt\")\n",
        "\n",
        "unpickled_ANYTHING_VAE = True #@param {'type':'boolean'}\n",
        "if unpickled_ANYTHING_VAE:\n",
        "  custom_hf_model(\"https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/Anything-V3.0.vae.pt\", \"un_anything.vae.pt\")\n",
        "\n",
        "orig_ANYTHING = False #@param {'type':'boolean'}\n",
        "if orig_ANYTHING:\n",
        "  custom_hf_model(\"https://huggingface.co/NoCrypt/Anything-v3-0/resolve/main/anything.ckpt\", \"anything.ckpt\")\n",
        "\n",
        "orig_ANYTHING_VAE = False #@param {'type':'boolean'}\n",
        "if orig_ANYTHING_VAE:\n",
        "  custom_hf_model(\"https://huggingface.co/NoCrypt/Anything-v3-0/resolve/main/anything.vae.pt\", \"anything.vae.pt\")\n",
        "\n",
        "#@markdown <font color=\"gray\"> . . *Why 2 anything? both outputs differently*\n",
        "\n",
        "Elysium_Anime_v2 = False #@param {'type':'boolean'}\n",
        "if Elysium_Anime_v2:\n",
        "  custom_hf_model(\"https://huggingface.co/hesw23168/SD-Elysium-Model/resolve/main/Elysium_Anime_V2.ckpt\", \"Elysium_Anime_V2.ckpt\")\n",
        "\n",
        "# Using Waifu-Diffusion VAE since it's recommended\n",
        "Elysium_Anime_v2_VAE = False #@param {'type':'boolean'}\n",
        "if Elysium_Anime_v2_VAE:\n",
        "  custom_hf_model(\"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime2.ckpt\", \"Elysium_Anime_V2.vae.pt\")\n",
        "\n",
        "gyokai = False #@param {'type':'boolean'}\n",
        "if gyokai:\n",
        "  custom_hf_model(\"https://huggingface.co/NoCrypt/gyokai/resolve/main/gyokai.ckpt\", \"gyokai.ckpt\")\n",
        "\n",
        "midjourney_v4_diffusion = False #@param {'type':'boolean'}\n",
        "if midjourney_v4_diffusion:\n",
        "  custom_hf_model(\"https://huggingface.co/prompthero/midjourney-v4-diffusion/resolve/main/mdjrny-v4.ckpt\", \"midjourney-v4-diffusion.ckpt\")\n",
        "\n",
        "cafe_instagram_unofficial_test = False #@param {'type':'boolean'}\n",
        "if cafe_instagram_unofficial_test:\n",
        "  custom_hf_model(\"https://huggingface.co/NoCrypt/cafe-instagram-unofficial/resolve/main/cafe-instagram-unofficial-test-epoch-9-140k-images-fp32.ckpt\", \"cafe-instagram-unofficial-test-epoch-9-140k-images-fp32.ckpt\")\n",
        "\n",
        "Trinart = False #@param {'type':'boolean'}\n",
        "if Trinart:\n",
        "  custom_hf_model(\"https://huggingface.co/naclbit/trinart_characters_19.2m_stable_diffusion_v1/resolve/main/trinart_characters_it4_v1.ckpt\", \"trinart.ckpt\")\n",
        "\n",
        "Trinart_VAE = False #@param {'type':'boolean'}\n",
        "if Trinart_VAE:\n",
        "  custom_hf_model(\"https://huggingface.co/naclbit/trinart_characters_19.2m_stable_diffusion_v1/resolve/main/autoencoder_fix_kl-f8-trinart_characters.ckpt\", \"trinart.vae.pt\")\n",
        "\n",
        "H_Diffusion_17 = False #@param {'type':'boolean'}\n",
        "if H_Diffusion_17:\n",
        "  custom_hf_model(\"https://huggingface.co/Deltaadams/HentaiDiffusion/resolve/main/HD-17.ckpt\", \"HD-17.ckpt\")\n",
        "\n",
        "SD_V1_4 = False #@param {'type':'boolean'}\n",
        "if SD_V1_4:\n",
        "  custom_hf_model(\"https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt\", \"stable_diffusion.ckpt\")\n",
        "\n",
        "SD_V1_5 = False #@param {'type':'boolean'}\n",
        "if SD_V1_5:\n",
        "  custom_hf_model(\"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt\", \"sd-v1-5.ckpt\")\n",
        "\n",
        "SD_V1_5_VAE = False #@param {'type':'boolean'}\n",
        "if SD_V1_5_VAE:\n",
        "  custom_hf_model(\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt\",\"sd-v1-5.vae.pt\")\n",
        "\n",
        "SD_v1_5_inpainting = False #@param {'type':'boolean'}\n",
        "if SD_v1_5_inpainting:\n",
        "  custom_hf_model(\"https://huggingface.co/runwayml/stable-diffusion-inpainting/resolve/main/sd-v1-5-inpainting.ckpt\", \"sd-v1-5-inpainting.ckpt\")\n",
        "\n",
        "custom_url = \"\" #@param {type:\"string\"}\n",
        "if custom_url:\n",
        "  custom_hf_model(custom_url)\n",
        "\n",
        "custom_url_2 = \"\" #@param {type:\"string\"}\n",
        "if custom_url_2:\n",
        "  custom_hf_model(custom_url_2)\n",
        "\n",
        "custom_url_HN = \"\" #@param {type:\"string\"}\n",
        "if custom_url_HN:\n",
        "  custom_hf_hn(custom_url_HN)\n",
        "\n",
        "custom_url_2_HN = \"\" #@param {type:\"string\"}\n",
        "if custom_url_2_HN:\n",
        "  custom_hf_hn(custom_url_2_HN)\n",
        "  \n",
        "custom_url_embedding = \"\" #@param {type:\"string\"}\n",
        "if custom_url_embedding:\n",
        "  custom_hf_em(custom_url_embedding)\n",
        "\n",
        "custom_url_embedding_2 = \"\" #@param {type:\"string\"}\n",
        "if custom_url_embedding_2:\n",
        "  custom_hf_em(custom_url_embedding_2)\n",
        "\n",
        "#------------------#\n",
        "\n",
        "#@markdown ## <br>**From Torrent, Magnet, and Other Direct Link ‚õìÔ∏èüß≤**\n",
        "\n",
        "\n",
        "def direct_model(url):\n",
        "  install_aria()\n",
        "  !aria2c --summary-interval=10 --seed-ratio=0.1 --allow-overwrite=true -d {root_dir}/stable-diffusion-webui/models/Stable-diffusion/ {url}\n",
        "  \n",
        "def direct_hn(url):\n",
        "  install_aria()\n",
        "  !aria2c --summary-interval=10 --seed-ratio=0.1 --allow-overwrite=true -d {root_dir}/stable-diffusion-webui/models/hypernetworks/ {url}\n",
        "\n",
        "def direct_em(url):\n",
        "  install_aria()\n",
        "  !aria2c --summary-interval=10 --seed-ratio=0.1 --allow-overwrite=true -d {root_dir}/stable-diffusion-webui/embeddings/ {url}\n",
        "\n",
        "file_url = \"\" #@param{'type':'string'}\n",
        "if file_url:\n",
        "  direct_model(file_url)\n",
        "\n",
        "file_url_2 = \"\" #@param{'type':'string'}\n",
        "if file_url_2:\n",
        "  direct_model(file_url_2)\n",
        "\n",
        "file_url_HN = \"\" #@param{'type':'string'}\n",
        "if file_url_HN:\n",
        "  direct_hn(file_url_HN)\n",
        "\n",
        "file_url_2_HN = \"\" #@param{'type':'string'}\n",
        "if file_url_2_HN:\n",
        "  direct_hn(file_url_2_HN)\n",
        "\n",
        "file_url_EM = \"\" #@param{'type':'string'}\n",
        "if file_url_EM:\n",
        "  direct_em(file_url_EM)\n",
        "\n",
        "file_url_2_EM = \"\" #@param{'type':'string'}\n",
        "if file_url_2_EM:\n",
        "  direct_em(file_url_2_EM)\n",
        "\n",
        "\n",
        "#------------------#\n",
        "\n",
        "#@markdown ## <br>**From Google Drive Link ‚öôÔ∏è**\n",
        "is_folder_url = False #@param{'type':'boolean'}\n",
        "def drive_link_model(url):\n",
        "  %cd {root_dir}/stable-diffusion-webui/models/Stable-diffusion/\n",
        "  if is_folder_url:\n",
        "    !gdown {url} -c -folder\n",
        "  else:\n",
        "    !gdown {url} -c\n",
        "  %cd\n",
        "\n",
        "def drive_link_hn(url):\n",
        "  %cd {root_dir}/stable-diffusion-webui/models/hypernetworks/\n",
        "  if is_folder_url:\n",
        "    !gdown {url} -c --folder\n",
        "  else:\n",
        "    !gdown {url} -c\n",
        "  %cd {root_dir}/stable-diffusion-webui/models/Stable-diffusion/\n",
        "\n",
        "def drive_link_em(url):\n",
        "  %cd {root_dir}/stable-diffusion-webui/embeddings/\n",
        "  if is_folder_url:\n",
        "    !gdown {url} -c --folder\n",
        "  else:\n",
        "    !gdown {url} -c\n",
        "  %cd {root_dir}/stable-diffusion-webui/models/Stable-diffusion/\n",
        "\n",
        "drive_url = \"\" #@param{'type':'string'}\n",
        "if drive_url:\n",
        "  drive_link_model(drive_url)\n",
        "\n",
        "drive_url_2 = \"\" #@param{'type':'string'}\n",
        "if drive_url_2:\n",
        "  drive_link_model(drive_url_2)\n",
        "\n",
        "drive_url_HN = \"\" #@param{'type':'string'}\n",
        "if drive_url_HN:\n",
        "  drive_link_hn(drive_url_HN)\n",
        "\n",
        "drive_url_2_HN = \"\" #@param{'type':'string'}\n",
        "if drive_url_2_HN:\n",
        "  drive_link_hn(drive_url_2_HN)\n",
        "\n",
        "drive_url_EM = \"\" #@param{'type':'string'}\n",
        "if drive_url_EM:\n",
        "  drive_link_em(drive_url_EM)\n",
        "\n",
        "drive_url_2_EM = \"\" #@param{'type':'string'}\n",
        "if drive_url_2_EM:\n",
        "  drive_link_em(drive_url_2_EM)\n",
        "\n",
        "#------------------#\n",
        "\n",
        "#@markdown ## <br>**From Your Google Drive üöã**\n",
        "#@markdown - /content/gdrive/MyDrive/`<the rest here, type it below>`\n",
        "#@markdown - for file, type the path. for folders, make sure to end it with `/.` <br>Example: `NAI/.`\n",
        "\n",
        "def gd_path(url):\n",
        "  if not os.path.exists('/content/gdrive'):\n",
        "    drive.mount('/content/gdrive')\n",
        "  !rsync -avr --progress \"/content/gdrive/MyDrive/{url}\" '/content/stable-diffusion-webui/models/Stable-diffusion' \n",
        "\n",
        "def gd_path_hn(url):\n",
        "  if not os.path.exists('/content/gdrive'):\n",
        "    drive.mount('/content/gdrive')\n",
        "  !rsync -avr --progress \"/content/gdrive/MyDrive/{url}\" '/content/stable-diffusion-webui/models/hypernetworks' \n",
        "\n",
        "def gd_path_em(url):\n",
        "  if not os.path.exists('/content/gdrive'):\n",
        "    drive.mount('/content/gdrive')\n",
        "  !rsync -avr --progress \"/content/gdrive/MyDrive/{url}\" '/content/stable-diffusion-webui/embeddings' \n",
        "\n",
        "drive_path = \"\" #@param{'type':'string'}\n",
        "if drive_path:\n",
        "  gd_path(drive_path)\n",
        "\n",
        "drive_path_2 = \"\" #@param{'type':'string'}\n",
        "if drive_path_2:\n",
        "  gd_path(drive_path_2)\n",
        "\n",
        "drive_path_HN = \"\" #@param{'type':'string'}\n",
        "if drive_path_HN:\n",
        "  gd_path_hn(drive_path_HN)\n",
        "\n",
        "drive_path_2_HN = \"\" #@param{'type':'string'}\n",
        "if drive_path_2_HN:\n",
        "  gd_path_hn(drive_path_2_HN)\n",
        "  \n",
        "drive_path_EM = \"\" #@param{'type':'string'}\n",
        "if drive_path_EM:\n",
        "  gd_path_em(drive_path_EM)\n",
        "\n",
        "drive_path_2_EM = \"\" #@param{'type':'string'}\n",
        "if drive_path_2_EM:\n",
        "  gd_path_em(drive_path_2_EM)\n",
        "\n",
        "#------------------#\n",
        "\n",
        "#@markdown ### <br>**Explaination**\n",
        "#@markdown - EM: Embeddings (Textual Inversion)\n",
        "#@markdown - HN: Hypernetworks\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RkggE82nGRlp"
      },
      "outputs": [],
      "source": [
        "#@title # **üöÄ Start webui**\n",
        "#@markdown ### **Select your server**\n",
        "server = \"localtunnel\" #@param [\"bore\",\"cloudflared\",\"localtunnel\",\"gradio\",\"ngrok\"]\n",
        "#@markdown  <font color=\"gray\">. . **Best to worst:** ngrok (need token tho) > cloudflared > bore > localtunnel > gradio (somtimes better)<br>\n",
        "%cd /content\n",
        "# This code is purely ((((ABSURD)))) and tends to broke after gradio update ü•≤ (IF ANYONE KNOW THE ALTERNATIVE PLEASE TELL ME üò≠, without freezing gradio version)\n",
        "!sed -i '/is_colab = /c\\            self.is_colab = False' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py\n",
        "\n",
        "share=''\n",
        "if server == \"gradio\":\n",
        "  share='--share'\n",
        "  !sed -i '/self.server_name = /c\\            self.server_name = server_name' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py\n",
        "  !sed -i '/self.server_port = /c\\            self.server_port = server_port' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py\n",
        "  !sed -i '/    else \"http/c\\                else \"http\"' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py\n",
        "  !sed -i '/\"PUBLIC_SHARE_TRUE\":/c\\    \"PUBLIC_SHARE_TRUE\": \"\u001b[32mConnected\",' /usr/local/lib/python3.7/dist-packages/gradio/strings.py\n",
        "\n",
        "elif server == \"localtunnel\":\n",
        "  if not os.path.exists('/tools/node/bin/lt'):\n",
        "    !npm install -g localtunnel\n",
        "  share=''\n",
        "  !nohup lt --port 7860 > srv.txt 2>&1 &\n",
        "  time.sleep(2)\n",
        "  !grep -o 'https[^ ]*' /content/srv.txt >srvr.txt\n",
        "  time.sleep(2)\n",
        "  srv= getoutput('cat /content/srvr.txt')\n",
        "  !sed -i '/self.server_name = /c\\            self.server_name = \"{srv[8:]}\"' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py\n",
        "  !sed -i '/self.server_port = /c\\            self.server_port = 443' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py\n",
        "  !sed -i '/    else \"http/c\\                else \"https\"' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py\n",
        "  !sed -i '/\"PUBLIC_SHARE_TRUE\":/c\\    \"PUBLIC_SHARE_TRUE\": \"\u001b[32mConnected\",' /usr/local/lib/python3.7/dist-packages/gradio/strings.py\n",
        "\n",
        "\n",
        "  !rm /content/srv.txt\n",
        "  !rm /content/srvr.txt\n",
        "elif server == \"cloudflared\":\n",
        "  if not os.path.exists('/usr/bin/cloudflared'):\n",
        "    !curl -Lo /usr/bin/cloudflared https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 && chmod +x /usr/bin/cloudflared\n",
        "  share=''\n",
        "  #keep trying untill get one! sorry cloudflare api üòÇ\n",
        "  while True:\n",
        "    !cloudflared tunnel --url localhost:7860 > clf.txt 2>&1 &\n",
        "    time.sleep(9)\n",
        "    !grep -m2 -o 'https[^ ]*' /content/clf.txt | tail -n1 > clfr.txt\n",
        "    srvs = getoutput('cat /content/clf.txt')\n",
        "    if \"has been created\" in srvs:\n",
        "      break\n",
        "    !rm /content/clf.txt\n",
        "    !rm /content/clfr.txt\n",
        "\n",
        "\n",
        "  srv= getoutput('cat /content/clfr.txt')\n",
        "  !sed -i '/self.server_name = /c\\            self.server_name = \"{srv[8:]}\"' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py\n",
        "  !sed -i '/self.server_port = /c\\            self.server_port = 443' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py\n",
        "  !sed -i '/    else \"http/c\\                else \"https\"' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py\n",
        "  !sed -i '/\"PUBLIC_SHARE_TRUE\":/c\\    \"PUBLIC_SHARE_TRUE\": \"\u001b[32mConnected\",' /usr/local/lib/python3.7/dist-packages/gradio/strings.py\n",
        "\n",
        "  \n",
        "  !rm /content/clf.txt\n",
        "  !rm /content/clfr.txt\n",
        "\n",
        "elif server == \"bore\":\n",
        "  if not os.path.exists('/usr/bin/bore'):\n",
        "    !curl -Ls https://github.com/ekzhang/bore/releases/download/v0.4.0/bore-v0.4.0-x86_64-unknown-linux-musl.tar.gz | tar zx -C /usr/bin\n",
        "  !bore local 7860 --to bore.pub > bore.txt 2>&1 &\n",
        "  time.sleep(2)\n",
        "  !grep -o -m1 'bore.pub:[^ ]*' /content/bore.txt > boreport.txt\n",
        "  boreport = getoutput('cat /content/boreport.txt')\n",
        "  !sed -i '/self.server_name = /c\\            self.server_name = \"bore.pub\"' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py\n",
        "  !sed -i '/self.server_port = /c\\            self.server_port = {boreport[9:]}' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py\n",
        "  !sed -i '/    else \"http/c\\                else \"http\"' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py\n",
        "  !sed -i '/\"PUBLIC_SHARE_TRUE\":/c\\    \"PUBLIC_SHARE_TRUE\": \"\u001b[32mConnected, using HTTP only!!\",' /usr/local/lib/python3.7/dist-packages/gradio/strings.py\n",
        "\n",
        "  \n",
        "  !rm /content/bore.txt\n",
        "  !rm /content/boreport.txt\n",
        "\n",
        "custom_arguments = \"\" #@param{\"type\":\"string\"}\n",
        "first_load_model = \"un_anything.ckpt\" #@param [\"anything.ckpt\", \"waifu_diffusion.ckpt\", \"gyokai.ckpt\", \"Elysium_Anime_V2.ckpt\", \"trinart.ckpt\", \"HD-17.ckpt\", \"stable_diffusion.ckpt\", \"sd-v1-5.ckpt\", \"sd-v1-5-inpainting.ckpt\" ] {allow-input: true}\n",
        "model_param = \"--ckpt \"+root_dir+\"/stable-diffusion-webui/models/Stable-diffusion/\"+first_load_model\n",
        "disable_safe_unpickle = True #@param{\"type\":\"boolean\"}\n",
        "if disable_safe_unpickle:\n",
        "  dsu_param = \"--disable-safe-unpickle\"\n",
        "else:\n",
        "  dsu_param = \"\"\n",
        "\n",
        "medvram = False #@param{\"type\":\"boolean\"}\n",
        "if medvram:\n",
        "  vram_param = \"--medvram\"\n",
        "else:\n",
        "  vram_param = \"\"\n",
        "\n",
        "precision_full_no_half = False #@param{\"type\":\"boolean\"}\n",
        "if precision_full_no_half:\n",
        "  precision_param = \"--precision full --no-half\"\n",
        "else:\n",
        "  precision_param = \"\"\n",
        "\n",
        "api = False #@param{\"type\":\"boolean\"}\n",
        "paint_hua_support = False #@param{\"type\":\"boolean\"}\n",
        "if paint_hua_support: \n",
        "  api_param = \"--api --cors-allow-origins=https://www.painthua.com\"\n",
        "else: \n",
        "  if api:\n",
        "    api_param = \"--api\"\n",
        "  else:\n",
        "    api_param = \"\"\n",
        "\n",
        "\n",
        "if xformers:\n",
        "  xformers_param = \"--xformers\"\n",
        "else:\n",
        "  xformers_param = \"\"\n",
        "\n",
        "# TODO: Make params a single variable, this is chaos.\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### **ngrok credentials (required if you use ngrok)**\n",
        "#@markdown [Get ngrok token here](https://dashboard.ngrok.com/get-started/your-authtoken) || [Region explaination](https://ngrok.com/docs/ngrok-agent/config#region)\n",
        "\n",
        "ngrok_token = \"\" #@param{type:\"string\"}\n",
        "ngrok_region = \"us\" #@param [\"us\", \"eu\", \"au\", \"ap\", \"sa\", \"jp\", \"in\"]\n",
        "if server == \"ngrok\":\n",
        "  # using https, so it's more secure.\n",
        "  !sed -i '/public_url = /c\\          public_url = ngrok.connect(port, pyngrok_config=config, bind_tls=True).public_url' {root_dir}/stable-diffusion-webui/modules/ngrok.py\n",
        "  share='--ngrok '+ngrok_token+' --ngrok-region '+ngrok_region\n",
        "\n",
        "%cd {root_dir}/stable-diffusion-webui\n",
        "!COMMANDLINE_ARGS=\"$custom_arguments\" REQS_FILE=\"requirements.txt\" python launch.py $share $dsu_param $vram_param $deepdanbooru_param $api_param $model_param $xformers_param $precision_param"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6B9e8Zxoj1N"
      },
      "source": [
        "# **‚öíÔ∏è Advanced Stuff**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "B977dVS6AZcL"
      },
      "outputs": [],
      "source": [
        "#@title # ‚ö†Ô∏è ***(ONLY RUN IF BROKEN)*** Run this if things broken\n",
        "#@markdown Please rerun \"Install Depedencies\" after running this.\n",
        "import os\n",
        "remove_repos = False #@param{type:'boolean'}\n",
        "if remove_repos: \n",
        "  # This will delete all repositories, just in case if its corrupted \n",
        "  !rm -rf {root_dir}/stable-diffusion-webui/repositories/ \n",
        "\n",
        "cleanup_experimentals = False #@param{type:'boolean'}\n",
        "if cleanup_experimentals:\n",
        "  # Just in case if you've used experimental options\n",
        "  !git checkout master\n",
        "  # !git branch --delete experimental_nc\n",
        "  !git reset --hard origin/master\n",
        "  !git pull\n",
        "\n",
        "remove_everything = True #@param{type:'boolean'}\n",
        "if remove_everything:\n",
        "  # Self-explanatory\n",
        "  !rm -rf {root_dir}/stable-diffusion-webui\n",
        "\n",
        "uninstall_xformers = True #@param{type:'boolean'}\n",
        "if uninstall_xformers:\n",
        "  # Self-explanatory, useful if you want to try hypernetworks\n",
        "  !pip uninstall xformers\n",
        "\n",
        "restart_runtime = False #@param{type:'boolean'}\n",
        "if restart_runtime:\n",
        "  # This will crash Colab (required if you want to free up ram n vram)\n",
        "  os.kill(os.getpid(), 9) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xSLziGY-sa89"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import clear_output\n",
        "!yes | pip install huggingface_hub --quiet\n",
        "from huggingface_hub import HfApi\n",
        "from huggingface_hub.utils import validate_repo_id\n",
        "\n",
        "models_path= root_dir+\"/stable-diffusion-webui/models/Stable-diffusion\"\n",
        "upload_path='/content/upload_models'\n",
        "\n",
        "#@title # **üöÄü§ó Upload models to HuggingFace**\n",
        "#@markdown ## **How to use this?**<br>\n",
        "#@markdown 1. Grab your huggingface **write token** from [here](https://huggingface.co/settings/tokens)\n",
        "#@markdown 2. Configure all settings down below\n",
        "#@markdown 3. Run the cell\n",
        "#@markdown 4. Select model you want to upload (use `ctrl/shift` for multiple selection)\n",
        "#@markdown 5. Click on upload button\n",
        "\n",
        "api = HfApi()\n",
        "write_token = \"\"  #@param{type:\"string\"}\n",
        "if not os.path.exists('/root/.huggingface/token'):\n",
        "  !mkdir /root/.huggingface/\n",
        "  !touch /root/.huggingface/token\n",
        "f = open(\"/root/.huggingface/token\", \"w+\")\n",
        "f.write(write_token)\n",
        "f.close()\n",
        "\n",
        "user = api.whoami(write_token)\n",
        "repo = \"models\" #@param{type:\"string\"}\n",
        "username_repo = user['name']+\"/\"+repo\n",
        "validate_repo_id(username_repo)\n",
        "is_new = \"new\" #@param[\"new\",\"existing\"]\n",
        "if is_new == \"new\":\n",
        "  api.create_repo(repo_id=username_repo)\n",
        "  \n",
        "#@markdown *If error, maybe you have \"read token\" instead of \"write token\", or the repo is already exists/not exists*\n",
        "def get_file_list(path):\n",
        "  res = []\n",
        "  for (dir_path, dir_names, file_names) in os.walk(path):\n",
        "      res.extend(file_names)\n",
        "  return res\n",
        "  \n",
        "selected = widgets.SelectMultiple(\n",
        "    options=get_file_list(models_path),\n",
        "    rows=10,\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "button = widgets.Button(\n",
        "    description='Upload',\n",
        "    disabled=False,\n",
        "    button_style='success',\n",
        "    tooltip='Upload to huggingface',\n",
        ")\n",
        "\n",
        "\n",
        "out = widgets.Output()\n",
        "\n",
        "def upload_it(b):\n",
        "    with out:\n",
        "        if selected.value is not None:\n",
        "            clear_output()\n",
        "            !mkdir -p {upload_path}\n",
        "\n",
        "            #hard link each file\n",
        "            for selected_model in selected.value:\n",
        "              if not os.path.exists(os.path.join(upload_path,selected_model)):\n",
        "                os.link(os.path.join(models_path,selected_model),os.path.join(upload_path,selected_model)) #hardlinking to save colab's space\n",
        "            \n",
        "            #delete .ipynb_checkpoint\n",
        "            if os.path.exists(os.path.join(upload_path,\".ipynb_checkpoints\")):\n",
        "              !rm {upload_path}/.ipynb_checkpoints\n",
        "            print(\"Selected:\", selected.value)\n",
        "            print(\"Uploading to https://huggingface.co/\"+username_repo)\n",
        "            print(\"Please wait...\")\n",
        "\n",
        "            #upload\n",
        "            api.upload_folder(\n",
        "                folder_path=upload_path,\n",
        "                repo_id=username_repo,\n",
        "            )\n",
        "            \n",
        "            print(\"Done!\")\n",
        "            #delete hardlink\n",
        "            !rm -rf {upload_path}/*\n",
        "\n",
        "        else:\n",
        "            print(\"Nothing is selected\")\n",
        "            b.close()\n",
        "            selected.close()\n",
        "\n",
        "button.on_click(upload_it)\n",
        "clear_output()\n",
        "print(\"Upload target: https://huggingface.co/\"+username_repo)\n",
        "print(\"üëá Select models you want to upload (use ctrl/shift for multiple selection) \")\n",
        "display(selected,button,out)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
	"accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
